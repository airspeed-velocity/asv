<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Writing benchmarks &mdash; airspeed velocity 0.1 documentation</title>
    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-3.2.0/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-3.2.0/css/bootstrap-theme.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.2.0/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="_static/swallow.ico"/>
    <link rel="top" title="airspeed velocity 0.1 documentation" href="index.html" />
    <link rel="next" title="Reference" href="reference.html" />
    <link rel="prev" title="Using airspeed velocity" href="using.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body>
  
  <a href="https://github.com/spacetelescope/asv"
     class="visible-desktop"><img
    style="position: absolute; top: 40px; right: 0; border: 0;"
    src="https://s3.amazonaws.com/github/ribbons/forkme_right_white_ffffff.png"
    alt="Fork me on GitHub"></a>


  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          airspeed velocity</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installing.html">Installing airspeed velocity</a></li>
<li class="toctree-l1"><a class="reference internal" href="using.html">Using airspeed velocity</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Writing benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="dev.html">Developer Docs</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Writing benchmarks</a><ul>
<li><a class="reference internal" href="#running-benchmarks-during-development">Running benchmarks during development</a></li>
<li><a class="reference internal" href="#setup-and-teardown-functions">Setup and teardown functions</a></li>
<li><a class="reference internal" href="#benchmark-attributes">Benchmark attributes</a></li>
<li><a class="reference internal" href="#parameterized-benchmarks">Parameterized benchmarks</a></li>
<li><a class="reference internal" href="#benchmark-types">Benchmark types</a><ul>
<li><a class="reference internal" href="#timing">Timing</a></li>
<li><a class="reference internal" href="#memory">Memory</a></li>
<li><a class="reference internal" href="#tracking-generic">Tracking (Generic)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="using.html" title="Previous Chapter: Using airspeed velocity"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Using airspeed v...</span>
    </a>
  </li>
  <li>
    <a href="reference.html" title="Next Chapter: Reference"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Reference &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12">
      
  <div class="section" id="writing-benchmarks">
<span id="id1"></span><h1>Writing benchmarks<a class="headerlink" href="#writing-benchmarks" title="Permalink to this headline">¶</a></h1>
<p>Benchmarks are stored in a collection of <tt class="docutils literal"><span class="pre">.py</span></tt> files in the
benchmark suite&#8217;s <tt class="docutils literal"><span class="pre">benchmark</span></tt> directory (as defined by
<tt class="docutils literal"><span class="pre">benchmark_dir</span></tt> in the <tt class="docutils literal"><span class="pre">asv.conf.json</span></tt> file).  They may be
arbitrarily nested in subdirectories, and all <tt class="docutils literal"><span class="pre">.py</span></tt> files will be
used, regardless of their file name.</p>
<p>Within each <tt class="docutils literal"><span class="pre">.py</span></tt> file, each benchmark is a function or method.  The
name of the functon must have a special prefix, depending on the type
of benchmark.  <tt class="docutils literal"><span class="pre">asv</span></tt> understands how to handle the prefix in either
<tt class="docutils literal"><span class="pre">CamelCase</span></tt> or lowercase with underscores.  For example, to create a
timing benchmark, the following are equivalent:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">time_range</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="k">def</span> <span class="nf">TimeRange</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="k">pass</span>
</pre></div>
</div>
<p>Benchmarks may be organized into methods of classes if desired:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">Suite</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">time_range</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
            <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">time_xrange</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
            <span class="k">pass</span>
</pre></div>
</div>
<div class="section" id="running-benchmarks-during-development">
<h2>Running benchmarks during development<a class="headerlink" href="#running-benchmarks-during-development" title="Permalink to this headline">¶</a></h2>
<p>There are some options to <tt class="docutils literal"><span class="pre">asv</span> <span class="pre">run</span></tt> that may be useful when writing
benchmarks.</p>
<p>You may find that <tt class="docutils literal"><span class="pre">asv</span> <span class="pre">run</span></tt> spends a lot of time setting up the
environment each time.  You can have <tt class="docutils literal"><span class="pre">asv</span> <span class="pre">run</span></tt> use an existing
Python environment that already has the benchmarked project and all of
its dependencies installed.  Use the <tt class="docutils literal"><span class="pre">--python</span></tt> argument to specify
a Python environment to use:</p>
<div class="highlight-python"><div class="highlight"><pre>asv run --python=python
</pre></div>
</div>
<p>If you don&#8217;t care about getting accurate timings, but just want to
ensure the code is running, you can add the <tt class="docutils literal"><span class="pre">--quick</span></tt> argument,
which will run each benchmark only once:</p>
<div class="highlight-python"><div class="highlight"><pre>asv run --quick
</pre></div>
</div>
<p>In order to display the standard error output (this includes exception tracebacks)
that your benchmarks may produce, pass the <tt class="docutils literal"><span class="pre">--show-stderr</span></tt> flag:</p>
<div class="highlight-python"><div class="highlight"><pre>asv run --show-stderr
</pre></div>
</div>
<p>Finally, there is a special command, <tt class="docutils literal"><span class="pre">asv</span> <span class="pre">dev</span></tt>, that uses all of
these features and is equivalent to:</p>
<div class="highlight-python"><div class="highlight"><pre>asv run --python=same --quick --show-stderr --dry-run
</pre></div>
</div>
</div>
<div class="section" id="setup-and-teardown-functions">
<h2>Setup and teardown functions<a class="headerlink" href="#setup-and-teardown-functions" title="Permalink to this headline">¶</a></h2>
<p>If initialization needs to be performed that should not be included in
the timing of the benchmark, include that code in a <tt class="docutils literal"><span class="pre">setup</span></tt> method
on the class, or set add an attribute called <tt class="docutils literal"><span class="pre">setup</span></tt> to a free
function.  For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">Suite</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c"># load data from a file</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;/usr/share/words.txt&quot;</span><span class="p">,</span> <span class="s">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">words</span> <span class="o">=</span> <span class="n">fd</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">time_upper</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">words</span><span class="p">:</span>
            <span class="n">word</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>

<span class="c"># or equivalently...</span>

<span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">def</span> <span class="nf">setup</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">words</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;/usr/share/words.txt&quot;</span><span class="p">,</span> <span class="s">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">fd</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">time_upper</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="n">word</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
<span class="n">time_upper</span><span class="o">.</span><span class="n">setup</span> <span class="o">=</span> <span class="n">setup</span>
</pre></div>
</div>
<p>You can also include a module-level <tt class="docutils literal"><span class="pre">setup</span></tt> function, which will be
run for every benchmark within the module, prior to any <tt class="docutils literal"><span class="pre">setup</span></tt>
assigned specifically to each function.</p>
<p>Similarly, benchmarks can also have a <tt class="docutils literal"><span class="pre">teardown</span></tt> function that is
run after the benchmark.  This is useful if, for example, you need to
clean up any changes made to the filesystem.  Generally, however, it
is not required: each benchmark runs in its own process, so any
tearing down of in-memory state happens automatically.</p>
</div>
<div class="section" id="benchmark-attributes">
<span id="id2"></span><h2>Benchmark attributes<a class="headerlink" href="#benchmark-attributes" title="Permalink to this headline">¶</a></h2>
<p>Each benchmark can have a number of arbitrary attributes assigned to
it.  The attributes that <tt class="docutils literal"><span class="pre">asv</span></tt> understands depends on the type of
benchmark and are defined below.  For free functions, just assign the
attribute to the function.  For methods, include the attribute at the
class level.  For example, the following are equivalent:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">time_range</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="k">pass</span>
<span class="n">time_range</span><span class="o">.</span><span class="n">timeout</span> <span class="o">=</span> <span class="mf">120.0</span>

<span class="k">class</span> <span class="nc">Suite</span><span class="p">:</span>
    <span class="n">timeout</span> <span class="o">=</span> <span class="mf">120.0</span>

    <span class="k">def</span> <span class="nf">time_range</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
            <span class="k">pass</span>
</pre></div>
</div>
<p>The following attributes are applicable to all benchmark types:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">timeout</span></tt>: The amount of time, in seconds, to give the benchmark
to run before forcibly killing it.  Defaults to 60 seconds.</li>
</ul>
</div>
<div class="section" id="parameterized-benchmarks">
<h2>Parameterized benchmarks<a class="headerlink" href="#parameterized-benchmarks" title="Permalink to this headline">¶</a></h2>
<p>You might want to run a single benchmark for multiple values of some
parameter. This can be done by adding a <tt class="docutils literal"><span class="pre">params</span></tt> attribute to the
benchmark object:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">time_range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
       <span class="k">pass</span>
<span class="n">time_range</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
</pre></div>
</div>
<p>This will also make the setup and teardown functions parameterized:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">Suite</span><span class="p">:</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">obj</span>

    <span class="k">def</span> <span class="nf">time_range_iter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">:</span>
            <span class="k">pass</span>
</pre></div>
</div>
<p>If <tt class="docutils literal"><span class="pre">setup</span></tt> raises a <tt class="docutils literal"><span class="pre">NotImplementedError</span></tt>, the test is skipped
for the parameter values in question.</p>
<p>The parameter values can be any Python objects. However, it is often
best to use only strings or numbers, because these have simple
unambiguous text representations.</p>
<p>When you have multiple parameters, the test is run for all
of their combinations:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">time_ranges</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">func_name</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;range&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">,</span> <span class="s">&#39;arange&#39;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">}[</span><span class="n">f</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">f</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="n">time_ranges</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="p">[</span><span class="s">&#39;range&#39;</span><span class="p">,</span> <span class="s">&#39;arange&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>The test will be run for parameters <tt class="docutils literal"><span class="pre">(10,</span> <span class="pre">'range'),</span> <span class="pre">(10,</span> <span class="pre">'arange'),</span>
<span class="pre">(1000,</span> <span class="pre">'range'),</span> <span class="pre">(1000,</span> <span class="pre">'arange')</span></tt>.</p>
<p>You can also provide informative names for the parameters:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">time_ranges</span><span class="o">.</span><span class="n">param_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;n&#39;</span><span class="p">,</span> <span class="s">&#39;function&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>These will appear in the test output; if not provided you get default
names such as &#8220;param1&#8221;, &#8220;param2&#8221;.</p>
</div>
<div class="section" id="benchmark-types">
<h2>Benchmark types<a class="headerlink" href="#benchmark-types" title="Permalink to this headline">¶</a></h2>
<div class="section" id="timing">
<h3>Timing<a class="headerlink" href="#timing" title="Permalink to this headline">¶</a></h3>
<p>Timing benchmarks have the prefix <tt class="docutils literal"><span class="pre">time</span></tt>.</p>
<p>The timing itself is based on the Python standard library&#8217;s <a class="reference external" href="http://docs.python.org/library/timeit.html#module-timeit" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">timeit</span></tt></a>
module, with some extensions for automatic heuristics shamelessly
stolen from IPython&#8217;s <a class="reference external" href="http://ipython.org/ipython-doc/dev/api/generated/IPython.core.magics.execution.html?highlight=timeit#IPython.core.magics.execution.ExecutionMagics.timeit">%timeit</a>
magic function.  This means that in most cases the benchmark function
itself will be run many times to achieve accurate timing.</p>
<p>The default timing function is the POSIX <tt class="docutils literal"><span class="pre">CLOCK_PROCESS_CPUTIME</span></tt>,
which measures the CPU time used only by the current process.  This is
available as <tt class="docutils literal"><span class="pre">time.process_time</span></tt> in Python 3.3 and later, but a
backport is included with <tt class="docutils literal"><span class="pre">asv</span></tt> for earlier versions of Python.</p>
<p>For best results, the benchmark function should contain as little as
possible, with as much extraneous setup moved to a <tt class="docutils literal"><span class="pre">setup</span></tt> function:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">Suite</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c"># load data from a file</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;/usr/share/words.txt&quot;</span><span class="p">,</span> <span class="s">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">words</span> <span class="o">=</span> <span class="n">fd</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">time_upper</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">words</span><span class="p">:</span>
            <span class="n">word</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Attributes</strong>:</p>
<ul>
<li><p class="first"><tt class="docutils literal"><span class="pre">goal_time</span></tt>: <tt class="docutils literal"><span class="pre">asv</span></tt> will automatically select the number of
iterations to run the benchmark so that it takes between
<tt class="docutils literal"><span class="pre">goal_time</span> <span class="pre">/</span> <span class="pre">10</span></tt> and <tt class="docutils literal"><span class="pre">goal_time</span></tt> seconds each time.  If not
specified, <tt class="docutils literal"><span class="pre">goal_time</span></tt> defaults to 2 seconds.</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">number</span></tt>: Manually choose the number of iterations.  If <tt class="docutils literal"><span class="pre">number</span></tt>
is specified, <tt class="docutils literal"><span class="pre">goal_time</span></tt> is ignored.</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">repeat</span></tt>: The number of times to repeat the benchmark, with each
repetition running the benchmark <tt class="docutils literal"><span class="pre">number</span></tt> of times.  The minimum
time from all of these repetitions is used as the final result.
When not provided, defaults to <tt class="docutils literal"><span class="pre">timeit.default_repeat</span></tt> (3).</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">timer</span></tt>: The timing function to use, which can be any source of
monotonically increasing numbers, such as <a class="reference external" href="http://docs.python.org/library/time.html#time.clock" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">time.clock</span></tt></a>, <a class="reference external" href="http://docs.python.org/library/time.html#time.time" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">time.time</span></tt></a>
or <tt class="docutils literal"><span class="pre">time.process_time</span></tt>.  If it&#8217;s not provided, it defaults to
<tt class="docutils literal"><span class="pre">time.process_time</span></tt> (or a backported version of it for versions of
Python prior to 3.3), but other useful values are
<a class="reference external" href="http://docs.python.org/library/timeit.html#timeit.default_timer" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">timeit.default_timer</span></tt></a> to use the default <tt class="docutils literal"><span class="pre">timeit</span></tt> behavior on
your version of Python.</p>
<p>On Windows, <a class="reference external" href="http://docs.python.org/library/time.html#time.clock" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">time.clock</span></tt></a> has microsecond granularity, but
<a class="reference external" href="http://docs.python.org/library/time.html#time.time" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">time.time</span></tt></a>&#8216;s granularity is 1/60th of a second. On Unix,
<a class="reference external" href="http://docs.python.org/library/time.html#time.clock" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">time.clock</span></tt></a> has 1/100th of a second granularity, and <a class="reference external" href="http://docs.python.org/library/time.html#time.time" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">time.time</span></tt></a> is
much more precise. On either platform, <a class="reference external" href="http://docs.python.org/library/timeit.html#timeit.default_timer" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">timeit.default_timer</span></tt></a>
measures wall clock time, not the CPU time. This means that other
processes running on the same computer may interfere with the
timing.  That&#8217;s why the default of <tt class="docutils literal"><span class="pre">time.process_time</span></tt>, which only
measures the time used by the current process, is often the best
choice.</p>
</li>
</ul>
<p>The <tt class="docutils literal"><span class="pre">goal_time</span></tt>, <tt class="docutils literal"><span class="pre">number</span></tt>, <tt class="docutils literal"><span class="pre">repeat</span></tt>, and <tt class="docutils literal"><span class="pre">timer</span></tt> attributes
can be adjusted in the <tt class="docutils literal"><span class="pre">setup()</span></tt> routine, which can be useful for
parameterized benchmarks.</p>
</div>
<div class="section" id="memory">
<h3>Memory<a class="headerlink" href="#memory" title="Permalink to this headline">¶</a></h3>
<p>Memory benchmarks have the prefix <tt class="docutils literal"><span class="pre">mem</span></tt>.</p>
<p>Memory benchmarks track the size of Python objects.  To write a memory
benchmark, write a function that returns the object you want to track:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">mem_list</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">256</span>
</pre></div>
</div>
<p>The <a class="reference external" href="http://pythonhosted.org/Pympler/asizeof.html">asizeof</a> module
is used to determine the size of Python objects.  Since <tt class="docutils literal"><span class="pre">asizeof</span></tt>
includes the memory of all of an object&#8217;s dependencies (including the
modules in which their classes are defined), a memory benchmark
instead calculates the incremental memory of a copy of the object,
which in most cases is probably a more useful indicator of how much
space <em>each additional</em> object will use.  If you need to do something
more specific, a generic <a class="reference internal" href="#tracking"><em>Tracking (Generic)</em></a> benchmark can be used
instead.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The memory benchmarking feature is still experimental.
<tt class="docutils literal"><span class="pre">asizeof</span></tt> may not be the most appropriate metric to use.</p>
</div>
</div>
<div class="section" id="tracking-generic">
<span id="tracking"></span><h3>Tracking (Generic)<a class="headerlink" href="#tracking-generic" title="Permalink to this headline">¶</a></h3>
<p>It is also possible to use <tt class="docutils literal"><span class="pre">asv</span></tt> to track any arbitrary numerical
value.  &#8220;Tracking&#8221; benchmarks can be used for this purpose and use the
prefix <tt class="docutils literal"><span class="pre">track</span></tt>.  These functions simply need to return a numeric
value.  For example, to track the number of objects known to the
garbage collector at a given state:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">gc</span>

<span class="k">def</span> <span class="nf">track_num_objects</span><span class="p">():</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">gc</span><span class="o">.</span><span class="n">get_objects</span><span class="p">())</span>
<span class="n">track_num_objects</span><span class="o">.</span><span class="n">unit</span> <span class="o">=</span> <span class="s">&quot;objects&quot;</span>
</pre></div>
</div>
<p><strong>Attributes</strong>:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">unit</span></tt>: The unit of the values returned by the benchmark.  Used
for display in the web interface.</li>
</ul>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2013, Michael Droettboom.<br/>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>