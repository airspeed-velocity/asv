<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Commands &mdash; airspeed velocity 0.1 documentation</title>
    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-3.2.0/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-3.2.0/css/bootstrap-theme.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.2.0/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="_static/swallow.ico"/>
    <link rel="top" title="airspeed velocity 0.1 documentation" href="index.html" />
    <link rel="up" title="Reference" href="reference.html" />
    <link rel="next" title="Developer Docs" href="dev.html" />
    <link rel="prev" title="asv.conf.json reference" href="asv.conf.json.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body>
  
  <a href="https://github.com/spacetelescope/asv"
     class="visible-desktop"><img
    style="position: absolute; top: 40px; right: 0; border: 0;"
    src="https://s3.amazonaws.com/github/ribbons/forkme_right_white_ffffff.png"
    alt="Fork me on GitHub"></a>


  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          airspeed velocity</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installing.html">Installing airspeed velocity</a></li>
<li class="toctree-l1"><a class="reference internal" href="using.html">Using airspeed velocity</a></li>
<li class="toctree-l1"><a class="reference internal" href="writing_benchmarks.html">Writing benchmarks</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="reference.html">Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="dev.html">Developer Docs</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Commands</a><ul>
<li><a class="reference internal" href="#asv-help">asv help</a></li>
<li><a class="reference internal" href="#asv-quickstart">asv quickstart</a></li>
<li><a class="reference internal" href="#asv-machine">asv machine</a></li>
<li><a class="reference internal" href="#asv-setup">asv setup</a></li>
<li><a class="reference internal" href="#asv-run">asv run</a></li>
<li><a class="reference internal" href="#asv-dev">asv dev</a></li>
<li><a class="reference internal" href="#asv-continuous">asv continuous</a></li>
<li><a class="reference internal" href="#asv-find">asv find</a></li>
<li><a class="reference internal" href="#asv-rm">asv rm</a></li>
<li><a class="reference internal" href="#asv-publish">asv publish</a></li>
<li><a class="reference internal" href="#asv-preview">asv preview</a></li>
<li><a class="reference internal" href="#asv-profile">asv profile</a></li>
<li><a class="reference internal" href="#asv-update">asv update</a></li>
<li><a class="reference internal" href="#asv-compare">asv compare</a></li>
<li><a class="reference internal" href="#asv-gh-pages">asv gh-pages</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="asv.conf.json.html" title="Previous Chapter: asv.conf.json reference"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; asv.conf.json re...</span>
    </a>
  </li>
  <li>
    <a href="dev.html" title="Next Chapter: Developer Docs"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Developer Docs &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12">
      
  <div class="section" id="module-asv.commands">
<span id="commands"></span><h1>Commands<a class="headerlink" href="#module-asv.commands" title="Permalink to this headline">¶</a></h1>
<div class="section" id="asv-help">
<h2>asv help<a class="headerlink" href="#asv-help" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv help [-h]

optional arguments:
  -h, --help  show this help message and exit
</pre></div>
</div>
</div>
<div class="section" id="asv-quickstart">
<h2>asv quickstart<a class="headerlink" href="#asv-quickstart" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv quickstart [-h] [--dest DEST]

Creates a new bechmarking suite

optional arguments:
  -h, --help            show this help message and exit
  --dest DEST, -d DEST  The destination directory for the new benchmarking
                        suite
</pre></div>
</div>
</div>
<div class="section" id="asv-machine">
<h2>asv machine<a class="headerlink" href="#asv-machine" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv machine [-h] [--machine MACHINE] [--os OS] [--arch ARCH]
                   [--cpu CPU] [--ram RAM]

Defines information about this machine. If no arguments are provided, an
interactive console session will be used to ask questions about the machine.

optional arguments:
  -h, --help         show this help message and exit
  --machine MACHINE  A unique name to identify this machine in the results.
                     May be anything, as long as it is unique across all the
                     machines used to benchmark this project. NOTE: If changed
                     from the default, it will no longer match the hostname of
                     this machine, and you may need to explicitly use the
                     --machine argument to asv.
  --os OS            The OS type and version of this machine. For example,
                     &#39;Macintosh OS-X 10.8&#39;.
  --arch ARCH        The generic CPU architecture of this machine. For
                     example, &#39;i386&#39; or &#39;x86_64&#39;.
  --cpu CPU          A specific description of the CPU of this machine,
                     including its speed and class. For example, &#39;Intel(R)
                     Core(TM) i5-2520M CPU @ 2.50GHz (4 cores)&#39;.
  --ram RAM          The amount of physical RAM on this machine. For example,
                     &#39;4GB&#39;.
</pre></div>
</div>
</div>
<div class="section" id="asv-setup">
<h2>asv setup<a class="headerlink" href="#asv-setup" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv setup [-h] [--parallel [PARALLEL]]

Setup virtual environments for each combination of Python version and third-
party requirement. This is called by the ``run`` command implicitly, and isn&#39;t
generally required to be run on its own.

optional arguments:
  -h, --help            show this help message and exit
  --parallel [PARALLEL], -j [PARALLEL]
                        Build (but don&#39;t benchmark) in parallel. The value is
                        the number of CPUs to use, or if no number provided,
                        use the number of cores on this machine.
</pre></div>
</div>
</div>
<div class="section" id="asv-run">
<h2>asv run<a class="headerlink" href="#asv-run" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv run [-h] [--steps STEPS] [--bench [BENCH]] [--profile]
               [--parallel [PARALLEL]] [--show-stderr] [--quick]
               [--python [PYTHON]] [--dry-run] [--machine [MACHINE]]
               [--skip-existing-successful] [--skip-existing-failed]
               [--skip-existing-commits] [--skip-existing]
               [range]

Run a benchmark suite.

positional arguments:
  range                 Range of commits to benchmark. For a git repository,
                        this is passed as the first argument to ``git log``.
                        See &#39;specifying ranges&#39; section of the `gitrevisions`
                        manpage for more info. Also accepts the special values
                        &#39;NEW&#39;, &#39;ALL&#39;, and &#39;EXISTING&#39;. &#39;NEW&#39; will benchmark all
                        commits since the latest benchmarked on this machine.
                        &#39;ALL&#39; will benchmark all commits in the project.
                        &#39;EXISTING&#39; will benchmark against all commits for
                        which there are existing benchmarks on any machine. By
                        default, will benchmark the head of the current master
                        branch.

optional arguments:
  -h, --help            show this help message and exit
  --steps STEPS, -s STEPS
                        Maximum number of steps to benchmark. This is used to
                        subsample the commits determined by range to a
                        reasonable number.
  --bench [BENCH], -b [BENCH]
                        Regular expression(s) for benchmark to run. When not
                        provided, all benchmarks are run.
  --profile, -p         In addition to timing, run the benchmarks through the
                        `cProfile` profiler and store the results.
  --parallel [PARALLEL], -j [PARALLEL]
                        Build (but don&#39;t benchmark) in parallel. The value is
                        the number of CPUs to use, or if no number provided,
                        use the number of cores on this machine.
  --show-stderr, -e     Display the stderr output from the benchmarks.
  --quick, -q           Do a &quot;quick&quot; run, where each benchmark function is run
                        only once. This is useful to find basic errors in the
                        benchmark functions faster. The results are unlikely
                        to be useful, and thus are not saved.
  --python [PYTHON]     Specify a Python interpreter in which to run the
                        benchmarks. It may be an executable to be searched for
                        on the $PATH, an absolute path, or the special value
                        &quot;same&quot; which will use the same Python interpreter that
                        asv is using. This interpreter must have the
                        benchmarked project already installed, including its
                        dependencies, and a specific revision of the
                        benchmarked project may not be provided. It may also
                        be any string accepted by any of the environment
                        plugins. For example, the conda plugin accepts &quot;2.7&quot;
                        to mean create a new Conda environment with Python
                        version 2.7.
  --dry-run, -n         Do not save any results to disk.
  --machine [MACHINE], -m [MACHINE]
                        Use the given name to retrieve machine information. If
                        not provided, the hostname is used. If that is not
                        found, and there is only one entry in ~/.asv-
                        machine.json, that one entry will be used.
  --skip-existing-successful
                        Skip running benchmarks that have previous successful
                        results
  --skip-existing-failed
                        Skip running benchmarks that have previous failed
                        results
  --skip-existing-commits
                        Skip running benchmarks for commits that have existing
                        results
  --skip-existing, -k   Skip running benchmarks that have previous successful
                        or failed results
</pre></div>
</div>
</div>
<div class="section" id="asv-dev">
<h2>asv dev<a class="headerlink" href="#asv-dev" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv dev [-h] [--bench [BENCH [BENCH ...]]] [--python [PYTHON]]
               [--machine [MACHINE]]

This runs a benchmark suite in a mode that is useful during development. It is
equivalent to ``asv run --quick --show-stderr --python=same``

optional arguments:
  -h, --help            show this help message and exit
  --bench [BENCH [BENCH ...]], -b [BENCH [BENCH ...]]
                        Regular expression(s) for benchmark to run. When not
                        provided, all benchmarks are run.
  --python [PYTHON]     Specify a Python interpreter in which to run the
                        benchmarks. By default, uses the same Python
                        interpreter that `asv` is using. It may be an
                        executable to be searched for on the $PATH, an
                        absolute path, or the special value &quot;same&quot; which will
                        use the same Python interpreter that asv is using.
                        This interpreter must have the benchmarked project
                        already installed, including its dependencies. A
                        specific revision may not be provided when --python is
                        provided.
  --machine [MACHINE], -m [MACHINE]
                        Use the given name to retrieve machine information. If
                        not provided, the hostname is used. If that is not
                        found, and there is only one entry in ~/.asv-
                        machine.json, that one entry will be used.
</pre></div>
</div>
</div>
<div class="section" id="asv-continuous">
<h2>asv continuous<a class="headerlink" href="#asv-continuous" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv continuous [-h] [--factor [FACTOR]] [--bench [BENCH [BENCH ...]]]
                      [--machine [MACHINE]]
                      branch

Run a side-by-side comparison of two commits for continuous integration.

positional arguments:
  branch                The HEAD branch to test. This commit and its parent
                        commit will be used as the two commits for comparison.

optional arguments:
  -h, --help            show this help message and exit
  --factor [FACTOR], -f [FACTOR]
                        The factor above or below which a result is considered
                        problematic. For example, with a factor of 2, if a
                        benchmark gets twice as slow or twice as fast, it will
                        be displayed in the results list.
  --bench [BENCH [BENCH ...]], -b [BENCH [BENCH ...]]
                        Regular expression(s) for benchmark to run. When not
                        provided, all benchmarks are run.
  --machine [MACHINE], -m [MACHINE]
                        Use the given name to retrieve machine information. If
                        not provided, the hostname is used. If no entry with
                        that name is found, and there is only one entry in
                        ~/.asv-machine.json, that one entry will be used.
</pre></div>
</div>
</div>
<div class="section" id="asv-find">
<h2>asv find<a class="headerlink" href="#asv-find" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv find [-h] [--invert] [--show-stderr] [--machine [MACHINE]]
                from..to benchmark_name

Adaptively searches a range of commits for one that produces a large
regression. This only works well when the regression in the range is mostly
monotonic.

positional arguments:
  from..to              Range of commits to search. For a git repository, this
                        is passed as the first argument to ``git log``. See
                        &#39;specifying ranges&#39; section of the `gitrevisions`
                        manpage for more info.
  benchmark_name        Name of benchmark to use in search.

optional arguments:
  -h, --help            show this help message and exit
  --invert, -i          Search for a decrease in the benchmark value, rather
                        than an increase.
  --show-stderr, -e     Display the stderr output from the benchmarks when
                        they fail.
  --machine [MACHINE], -m [MACHINE]
                        Use the given name to retrieve machine information. If
                        not provided, the hostname is used. If that is not
                        found, and there is only one entry in ~/.asv-
                        machine.json, that one entry will be used.
</pre></div>
</div>
</div>
<div class="section" id="asv-rm">
<h2>asv rm<a class="headerlink" href="#asv-rm" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv rm [-h] [-y] [patterns [patterns ...]]

Removes entries from the results database.

positional arguments:
  patterns    Pattern(s) to match, each of the form X=Y. X may be one of
              &quot;benchmark&quot;, &quot;commit_hash&quot;, &quot;python&quot; or any of the machine or
              environment params. Y is a case-sensitive glob pattern.

optional arguments:
  -h, --help  show this help message and exit
  -y          Don&#39;t prompt for confirmation.
</pre></div>
</div>
</div>
<div class="section" id="asv-publish">
<h2>asv publish<a class="headerlink" href="#asv-publish" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv publish [-h]

Collate all results into a website. This website will be written to the
``html_dir`` given in the ``asv.conf.json`` file, and may be served using any
static web server.

optional arguments:
  -h, --help  show this help message and exit
</pre></div>
</div>
</div>
<div class="section" id="asv-preview">
<h2>asv preview<a class="headerlink" href="#asv-preview" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv preview [-h] [--port PORT] [--browser]

Preview the results using a local web server

optional arguments:
  -h, --help            show this help message and exit
  --port PORT, -p PORT  Port to run webserver on. [8080]
  --browser, -b         Open in webbrowser
</pre></div>
</div>
</div>
<div class="section" id="asv-profile">
<h2>asv profile<a class="headerlink" href="#asv-profile" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv profile [-h] [--gui [GUI]] [--output [OUTPUT]] [--force]
                   [--environment [ENVIRONMENT]] [--python [PYTHON]]
                   [benchmark] [revision]

Profile a benchmark

positional arguments:
  benchmark             The benchmark to profile. Must be a fully-specified
                        benchmark name.
  revision              The revision of the project to profile. May be a
                        commit hash, or a tag or branch name.

optional arguments:
  -h, --help            show this help message and exit
  --gui [GUI], -g [GUI]
                        Display the profile in the given gui. Use --gui=list
                        to list available guis.
  --output [OUTPUT], -o [OUTPUT]
                        Save the profiling information to the given file. This
                        file is in the format written by the `cProfile`
                        standard library module. If not provided, prints a
                        simple text-based profiling report to the console.
  --force, -f           Forcibly re-run the profile, even if the data already
                        exists in the results database.
  --environment [ENVIRONMENT], -e [ENVIRONMENT]
                        Which environment to use. Your benchmarking project
                        may have multiple environments if it has a dependency
                        matrix or multiple versions of Python specified. This
                        should the name of an environment directory as already
                        created by the run command. If `None` is specified,
                        one will be chosen at random.
  --python [PYTHON]     Specify a Python interpreter in which to run the
                        benchmarks. It may be an executable to be searched for
                        on the $PATH, an absolute path, or the special value
                        &quot;same&quot; which will use the same Python interpreter that
                        asv is using. This interpreter must have the
                        benchmarked project already installed, including its
                        dependencies, and a specific revision of the
                        benchmarked project may not be provided. It may also
                        be any string accepted by any of the environment
                        plugins. For example, the conda plugin accepts &quot;2.7&quot;
                        to mean create a new Conda environment with Python
                        version 2.7.
</pre></div>
</div>
</div>
<div class="section" id="asv-update">
<h2>asv update<a class="headerlink" href="#asv-update" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv update [-h]

Update the results and config files to the current version

optional arguments:
  -h, --help  show this help message and exit
</pre></div>
</div>
</div>
<div class="section" id="asv-compare">
<h2>asv compare<a class="headerlink" href="#asv-compare" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv compare [-h] [--threshold [THRESHOLD]] [--split]
                   [--machine [MACHINE]]
                   revision1 revision2

Compare two sets of results

positional arguments:
  revision1             The reference revision.
  revision2             The revision being compared

optional arguments:
  -h, --help            show this help message and exit
  --threshold [THRESHOLD], -t [THRESHOLD]
                        The threshold to use to color-code divergent results.
                        This is a factor, so for example setting this to 2
                        will highlight all results differing by more than a
                        factor of 2.
  --split, -s           Split the output into a table of benchmarks that have
                        improved, stayed the same, and gotten worse
  --machine [MACHINE], -m [MACHINE]
                        The machine to compare the revisions for
</pre></div>
</div>
</div>
<div class="section" id="asv-gh-pages">
<h2>asv gh-pages<a class="headerlink" href="#asv-gh-pages" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre>usage: asv gh-pages [-h]

Publish the results to github pages

optional arguments:
  -h, --help  show this help message and exit
</pre></div>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2013, Michael Droettboom.<br/>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>